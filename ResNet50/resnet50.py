# -*- coding: utf-8 -*-
"""ResNet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16gfHm1LwQRLP9IORpgB9VHe1uKuvSb-j
"""

import numpy as np
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import matplotlib.pyplot as plt
import imageio

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Specify transforms using torchvision.transforms as transforms library


transformations = transforms.Compose([
    transforms.Resize(255),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

from google.colab import drive
drive.mount('/content/drive')

train_set = datasets.ImageFolder("/content/drive/MyDrive/dataset/Training", transform = transformations)
val_set = datasets.ImageFolder("/content/drive/MyDrive/dataset/Testing", transform = transformations)

len(val_set)

len(train_set)

class_names  = train_set.classes

# Creating Data_Loader with a batch size of 32
train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_set, batch_size =32, shuffle=True)

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
imshow(torchvision.utils.make_grid(images))

for images, labels in train_loader:
    # Show images
    imshow(torchvision.utils.make_grid(images))
    break  # Exit loop after one iteration to get only one batch of images and labels

model = models.resnet50(pretrained= True)

model.to(device)

#Using the pretrained model we Dont Train the initial layers.
for param in model.parameters():
    param.requires_grad = True #Set True to train the whole network

# Creating final fully connected Layer that accorting to the no of classes we require
# When training the complete model on our own dataset , we omit the the following sequential layer
model.fc = nn.Sequential(nn.Linear(2048, 512),
                                 nn.ReLU(),
                                 nn.Dropout(0.2),
                                 nn.Linear(512,len(class_names)),
                                 nn.LogSoftmax(dim=1))

# Loss and optimizer
criterion = nn.NLLLoss()
#optimizer = optim.SGD(model.fc.parameters(), lr=0.01)

optimizer = optim.SGD([
        {'params': model.conv1.parameters(), 'lr':1e-4},
        {'params': model.layer1.parameters(), 'lr':1e-4},
        {'params': model.layer2.parameters(),'lr':1e-4},
        {'params': model.layer3.parameters(),'lr':1e-3},
        {'params': model.layer4.parameters() ,'lr':1e-3},
        {'params': model.fc.parameters(), 'lr': 1e-2}   # the classifier needs to learn weights faster
    ], lr=0.001, weight_decay=0.0005)

from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts

# Restarts the learning rate after every 5 epoch
scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0= 5,
        T_mult= 1,
    )

epochs = 5
best_acc = 0.0
iters = len(train_loader)

train_loss, val_loss = [], []

import matplotlib.pyplot as plt
import time

# Initialize lists to store training and validation loss
train_loss = []
val_loss = []

for epoch in range(epochs):

    train_loss_epoch = 0
    valid_loss_epoch = 0
    accuracy = 0

    # Training the model
    model.train()
    running_loss = 0.0
    running_corrects = 0
    start_time = time.time()
    for i, (inputs, labels) in enumerate(train_loader, 1):
        # Move inputs and labels to device
        inputs, labels = inputs.to(device), labels.to(device)

        # Clear gradients
        optimizer.zero_grad()
        model.to(device)
        # Forward pass
        outputs = model(inputs)

        # Calculate loss
        loss = criterion(outputs, labels)

        # Backpropagation
        loss.backward()

        # Update weights
        optimizer.step()

        # Add the loss to the training set's running loss
        running_loss += loss.item() * inputs.size(0)

        # Calculate accuracy
        _, preds = torch.max(outputs, 1)
        running_corrects += torch.sum(preds == labels.data)

    # Calculate epoch loss and accuracy
    epoch_loss = running_loss / len(train_set)
    epoch_acc = running_corrects.double() / len(train_set)
    train_loss.append(epoch_loss)
    print(f'Epoch {epoch+1}/{epochs}')
    print(f'{len(train_loader)}/{len(train_loader)} [==============================]', end='')
    print(f' - {time.time() - start_time:.0f}s/step', end='')
    print(f' - loss: {epoch_loss:.4f} - accuracy: {epoch_acc:.4f}', end='')

    # Evaluating the model
    model.eval()
    running_loss = 0.0
    running_corrects = 0

    # Tell torch not to calculate gradients
    with torch.no_grad():

        for inputs, labels in val_loader:
            # Move inputs and labels to device
            inputs, labels = inputs.to(device), labels.to(device)

            # Forward pass
            outputs = model(inputs)

            # Calculate loss
            val_loss_batch = criterion(outputs, labels)

            # Add loss to the validation set's running loss
            valid_loss_epoch += val_loss_batch.item() * inputs.size(0)

    # Calculate average validation loss
    epoch_val_loss = valid_loss_epoch / len(val_set)
    val_loss.append(epoch_val_loss)

    print(f'Epoch [{epoch + 1}/{epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}')

# Save the trained model
torch.save(model.state_dict(), 'trained_model.pth')

# Load the trained model
model.load_state_dict(torch.load('trained_model.pth'))
model.eval()

# Testing the model
correct = 0
total = 0
with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the test images: {100 * correct / total}%')

import torchvision.transforms as transforms
from PIL import Image

# Define image transformations
image_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load and preprocess the input image
input_image = Image.open('/content/drive/MyDrive/rust (365).jpeg')  # Change 'input_image.jpg' to the path of your input image
input_tensor = image_transforms(input_image)
input_batch = input_tensor.unsqueeze(0)  # Add batch dimension



# Perform inference
with torch.no_grad():
    output = model(input_batch)
    probabilities = torch.exp(output)
    predicted_class = torch.argmax(probabilities).item()

# Get the predicted class label
predicted_label = class_names[predicted_class]
print('Predicted Class:', predicted_label)